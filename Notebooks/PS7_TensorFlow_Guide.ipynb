{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Guide\n",
    "\n",
    "[From the TensorFlow Low Level Intro](https://www.tensorflow.org/guide/low_level_intro)\n",
    "\n",
    "1. [Low Level Intro](#intro)\n",
    "2. [Tensors](#tensors)\n",
    "3. [Variables](#variables)\n",
    "4. [Graphs and Sessions](#graphs)\n",
    "5. [Save and Restore](#save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "# Introduction\n",
    "\n",
    "## Tensors\n",
    "\n",
    "Scalars, Vectors, Matrices, etc.\n",
    "\n",
    "## TF Core\n",
    "\n",
    "1. Building computational graph\n",
    "    * Operations: consume/produce tensors (nodes)\n",
    "    * Tensors: values that flow through graph (edges)\n",
    "        * Don't have actual values, handle elements in graph.\n",
    "2. Running the graph\n",
    "    * tf.Session\n",
    "    * Runs all the operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Example of building a simple graph \n",
    "\n",
    "a = tf.constant(3.0, dtype=tf.float32)\n",
    "b = tf.constant(4.0) # also tf.float32 implicitly\n",
    "total = a + b\n",
    "print(a)\n",
    "print(b)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard\n",
    "\n",
    "Visualizing a computation graph.\n",
    "\n",
    "Run tensorboard --logdir . from the command line  \n",
    "\n",
    "Visit the [graphs page](http://localhost:6006/#graphs) to see the current graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('.')\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a Session\n",
    "\n",
    "Use the run method to run sessions. During a run, tf tensor assigned a single value.\n",
    "\n",
    "Can handle multiple tensors, or tuples and dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "\n",
      "{'ab': (3.0, 4.0), 'total': 7.0}\n",
      "\n",
      "[0.21971369 0.12934744 0.6974678 ]\n",
      "\n",
      "[0.7522409  0.32861328 0.44966292]\n",
      "\n",
      "(array([1.4715741, 1.2332177, 1.2504699], dtype=float32), array([2.471574 , 2.2332177, 2.25047  ], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# Example sessions\n",
    "sess = tf.Session()\n",
    "print(sess.run(total))\n",
    "print()\n",
    "\n",
    "print(sess.run({'ab':(a, b), 'total':total}))\n",
    "print()\n",
    "\n",
    "vec = tf.random_uniform(shape=(3,))\n",
    "out1 = vec + 1\n",
    "out2 = vec + 2\n",
    "print(sess.run(vec))\n",
    "print()\n",
    "# New session resets the random numbers\n",
    "print(sess.run(vec))\n",
    "print()\n",
    "# But stays consistent during a single run\n",
    "print(sess.run((out1, out2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding\n",
    "\n",
    "Can use placeholders instead of constants. \n",
    "\n",
    "* Use feed_dict argument to send in variable values.\n",
    "* Can overwrite any tensor in the graph.\n",
    "\n",
    "Can also use data instead of placeholders for more complex models.\n",
    "\n",
    "* Need to make an iterator.\n",
    "* Use make_one_shot_iterator method\n",
    "* Might need to initialize iterator first if data depends on operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "# Use placeholders to assign variables\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "z = x + y\n",
    "\n",
    "print(sess.run(z, feed_dict={x: 3, y: 4.5}))\n",
    "print(sess.run(z, feed_dict={x: [1, 3], y: [2, 4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[2 3]\n",
      "[4 5]\n",
      "[6 7]\n",
      "End of data\n",
      "\n",
      "[ 0.52168643  1.4267836  -1.079171  ]\n",
      "[-0.0398622   1.45702    -0.31765458]\n",
      "[-0.53401935 -0.7407698   0.888094  ]\n",
      "[0.51265025 0.13362586 1.26846   ]\n",
      "[ 0.81480944 -0.96578735  0.5240727 ]\n",
      "[-0.22211717  0.01251148  0.00614682]\n",
      "[ 0.17489392 -0.43458703 -1.1202222 ]\n",
      "[ 1.4680849  -0.34176132 -1.169173  ]\n",
      "[-0.74166256  0.4095481  -0.88163054]\n",
      "[-2.399935   1.8603909 -0.7541033]\n",
      "End of data\n"
     ]
    }
   ],
   "source": [
    "# TF data\n",
    "my_data = [\n",
    "    [0, 1,],\n",
    "    [2, 3,],\n",
    "    [4, 5,],\n",
    "    [6, 7,],\n",
    "]\n",
    "slices = tf.data.Dataset.from_tensor_slices(my_data)\n",
    "next_item = slices.make_one_shot_iterator().get_next()\n",
    "\n",
    "while True:\n",
    "  try:\n",
    "    print(sess.run(next_item))\n",
    "  except tf.errors.OutOfRangeError:\n",
    "    print('End of data')\n",
    "    break\n",
    "    \n",
    "print()\n",
    "\n",
    "    \n",
    "# Initalize iterator first\n",
    "r = tf.random_normal([10,3])\n",
    "dataset = tf.data.Dataset.from_tensor_slices(r)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_row = iterator.get_next()\n",
    "\n",
    "sess.run(iterator.initializer)\n",
    "while True:\n",
    "  try:\n",
    "    print(sess.run(next_row))\n",
    "  except tf.errors.OutOfRangeError:\n",
    "    print('End of data')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers\n",
    "\n",
    "Preferred way to add trainable parameters to a graph.\n",
    "\n",
    "Package variables and operators that act on them. \n",
    "\n",
    "Must initialize variables before we can use them. \n",
    "* global_variables_initializer only initializes variables that existed in graph when initializer was created (create it last)\n",
    "\n",
    "Some shortcuts exist: eg Dense shortcut is dense.\n",
    "* Create and run layer in single cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4131797]\n",
      " [0.7181771]]\n"
     ]
    }
   ],
   "source": [
    "# Creating Layers\n",
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "linear_model = tf.layers.Dense(units=1)\n",
    "y = linear_model(x)\n",
    "\n",
    "# Initialize all variables and run graph.\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Execute Layers\n",
    "print(sess.run(y, {x: [[1, 2, 3],[4, 5, 6]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10449862]\n",
      " [-0.47251987]]\n"
     ]
    }
   ],
   "source": [
    "# Shortcut method\n",
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.layers.dense(x, units=1)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Columns\n",
    "\n",
    "Can play with the columns if you want.\n",
    "\n",
    "* feature_column.input_layer\n",
    "* Need to wrap categorical columns in an indicator column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aron\\Anaconda3\\envs\\datascience\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "[[ 1.  0.  5.]\n",
      " [ 1.  0. 10.]\n",
      " [ 0.  1.  8.]\n",
      " [ 0.  1.  9.]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "features = {\n",
    "    'sales' : [[5], [10], [8], [9]],\n",
    "    'department': ['sports', 'sports', 'gardening', 'gardening']}\n",
    "\n",
    "department_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'department', ['sports', 'gardening'])\n",
    "department_column = tf.feature_column.indicator_column(department_column)\n",
    "\n",
    "columns = [\n",
    "    tf.feature_column.numeric_column('sales'),\n",
    "    department_column\n",
    "]\n",
    "\n",
    "inputs = tf.feature_column.input_layer(features, columns)\n",
    "\n",
    "# Remember to initialize variables (required for categorical)\n",
    "var_init = tf.global_variables_initializer()\n",
    "table_init = tf.tables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run((var_init, table_init))\n",
    "\n",
    "# Run it\n",
    "print(sess.run(inputs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "1. Define data\n",
    "2. Define model\n",
    "3. Define loss\n",
    "4. Define optimizer\n",
    "    * Will automatically update variables to minimize the loss.\n",
    "5. Run and see loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.787796\n",
      "3.3509994\n",
      "2.3538651\n",
      "1.6618035\n",
      "1.1814256\n",
      "0.8479322\n",
      "0.6163598\n",
      "0.45550904\n",
      "0.34373167\n",
      "0.26600638\n",
      "[[-0.63878775]\n",
      " [-1.5025278 ]\n",
      " [-2.366268  ]\n",
      " [-3.230008  ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)\n",
    "y_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)\n",
    "\n",
    "linear_model = tf.layers.Dense(units=1)\n",
    "\n",
    "y_pred = linear_model(x)\n",
    "loss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(10):\n",
    "  _, loss_value = sess.run((train, loss))\n",
    "  print(loss_value)\n",
    "\n",
    "print(sess.run(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tensors'></a>\n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "# Tensors\n",
    "\n",
    "Main computational element passed through grahphs. tf.Tensor has:\n",
    "* data type: float32, int32, etc. Always known.\n",
    "    * Can only ever have 1 type per tensor. (eg all strings, all ints, etc). \n",
    "    * Can cast into different datatypes\n",
    "    * Converts python integers to tf.int32\n",
    "    * Converts python floating point to tf.float32 (unless otherwise specified)\n",
    "* shape: Can be partially unknown (eg. don't know number of examples to feed in). \n",
    "    * Can access either via the tf.Tensor.shape method or\n",
    "    * tf.shape operation (ie tf.shape(tensor))\n",
    "    * Can reshape like numpy arrays\n",
    "* rank: number of dimensions\n",
    "     * 0 = scalar\n",
    "     * 1 = vector\n",
    "     * 2 = matrix\n",
    "     * ... etc\n",
    "\n",
    "Special tensors:\n",
    "* tf.Variable\n",
    "* tf.constant\n",
    "* tf.placeholder\n",
    "* tf.SpareTensor\n",
    "\n",
    "Can access slices the same way as regular python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0\n",
      "<tf.Variable 'Variable_1:0' shape=() dtype=int32_ref>\n",
      "()\n",
      "Tensor(\"Rank:0\", shape=(), dtype=int32)\n",
      "\n",
      "Rank 1\n",
      "<tf.Variable 'Variable_4:0' shape=(1,) dtype=string_ref>\n",
      "(1,)\n",
      "Tensor(\"Rank_1:0\", shape=(), dtype=int32)\n",
      "\n",
      "Rank 2\n",
      "<tf.Variable 'Variable_8:0' shape=(2, 1) dtype=int32_ref>\n",
      "(2, 1)\n",
      "Tensor(\"Rank_3:0\", shape=(), dtype=int32)\n",
      "\n",
      "Higher Rank\n",
      "Tensor(\"zeros:0\", shape=(10, 299, 299, 3), dtype=float32)\n",
      "(10, 299, 299, 3)\n",
      "Tensor(\"Rank_4:0\", shape=(), dtype=int32)\n",
      "\n",
      "Run session to get actual rank: 4\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(10), Dimension(299), Dimension(299), Dimension(3)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank 0 Examples\n",
    "mammal = tf.Variable(\"Elephant\", tf.string)\n",
    "ignition = tf.Variable(451, tf.int16)\n",
    "floating = tf.Variable(3.14159265359, tf.float64)\n",
    "its_complicated = tf.Variable(12.3 - 4.85j, tf.complex64)\n",
    "\n",
    "print('Rank 0')\n",
    "print(ignition)\n",
    "print(ignition.shape)\n",
    "print(tf.rank(ignition))\n",
    "print()\n",
    "\n",
    "# Rank 1 Examples\n",
    "mystr = tf.Variable([\"Hello\"], tf.string)\n",
    "cool_numbers  = tf.Variable([3.14159, 2.71828], tf.float32)\n",
    "first_primes = tf.Variable([2, 3, 5, 7, 11], tf.int32)\n",
    "its_very_complicated = tf.Variable([12.3 - 4.85j, 7.5 - 6.23j], tf.complex64)\n",
    "\n",
    "print('Rank 1')\n",
    "print(mystr)\n",
    "print(mystr.shape)\n",
    "print(tf.rank(mystr))\n",
    "print()\n",
    "\n",
    "# Rank 2\n",
    "\n",
    "mymat = tf.Variable([[7],[11]], tf.int16)\n",
    "myxor = tf.Variable([[False, True],[True, False]], tf.bool)\n",
    "linear_squares = tf.Variable([[4], [9], [16], [25]], tf.int32)\n",
    "squarish_squares = tf.Variable([ [4, 9], [16, 25] ], tf.int32)\n",
    "rank_of_squares = tf.rank(squarish_squares)\n",
    "mymatC = tf.Variable([[7],[11]], tf.int32)\n",
    "\n",
    "print('Rank 2')\n",
    "print(mymat)\n",
    "print(mymat.shape)\n",
    "print(tf.rank(mymat))\n",
    "print()\n",
    "\n",
    "# And higher\n",
    "# Images often rank 4 (batch x width x height x rgb)\n",
    "my_image = tf.zeros([10, 299, 299, 3])  \n",
    "\n",
    "print('Higher Rank')\n",
    "print(my_image)\n",
    "print(my_image.shape)\n",
    "print(tf.rank(my_image))\n",
    "print()\n",
    "\n",
    "print(\"Run session to get actual rank: %d\"%sess.run(tf.rank(my_image)))\n",
    "print()\n",
    "\n",
    "my_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 5)\n",
      "(6, 10)\n",
      "(3, 20)\n",
      "(4, 3, 5)\n",
      "Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping a tensor\n",
    "rank_three_tensor = tf.ones([3, 4, 5])\n",
    "matrix = tf.reshape(rank_three_tensor, [6, 10])  # Reshape existing content into\n",
    "                                                 # a 6x10 matrix\n",
    "matrixB = tf.reshape(matrix, [3, -1])  #  Reshape existing content into a 3x20\n",
    "                                       # matrix. -1 tells reshape to calculate\n",
    "                                       # the size of this dimension.\n",
    "matrixAlt = tf.reshape(matrixB, [4, 3, -1])  # Reshape existing content into a\n",
    "                                             #4x3x5 tensor\n",
    "    \n",
    "print(rank_three_tensor.shape)\n",
    "print(matrix.shape)\n",
    "print(matrixB.shape)\n",
    "print(matrixAlt.shape)\n",
    "\n",
    "print(tf.shape(matrixAlt))\n",
    "\n",
    "# Note that the number of elements of the reshaped Tensors has to match the\n",
    "# original number of elements. Therefore, the following example generates an\n",
    "# error because no possible value for the last dimension will match the number\n",
    "# of elements.\n",
    "# ERROR::: yet_another = tf.reshape(matrixAlt, [13, 2, -1])  # ERROR!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int32'>\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Data Type Conversion \n",
    "# Cast a constant integer tensor into floating point.\n",
    "float_tensor = tf.cast(tf.constant([1, 2, 3]), dtype=tf.float32)\n",
    "print(tf.constant([1,2,3]).dtype)\n",
    "print(float_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Tensors\n",
    "\n",
    "Can fetch assigned values using the eval method. \n",
    "\n",
    "* only works when a default tf.Session is active\n",
    "* may fail if dynamic information is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 9]\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# Start a session and evaluate a tensor\n",
    "sess = tf.Session()\n",
    "constant = tf.constant([1, 2, 3])\n",
    "tensor = constant * constant\n",
    "print(tensor.eval(session=sess))\n",
    "\n",
    "# Need to assign placeholder values\n",
    "p = tf.placeholder(tf.float32)\n",
    "t = p + 1.0\n",
    "\n",
    "# t.eval()  # This will fail, since the placeholder did not get a value.\n",
    "print(t.eval(session = sess, feed_dict={p:2.0}))  # This will succeed because we're feeding a value\n",
    "                           # to the placeholder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing Tensors \n",
    "\n",
    "Don't use print, use tf.Print and its return value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-8925c6e50d8f>:2: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
      "Instructions for updating:\n",
      "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
      "```python\n",
      "    sess = tf.Session()\n",
      "    with sess.as_default():\n",
      "        tensor = tf.range(10)\n",
      "        print_op = tf.print(tensor)\n",
      "        with tf.control_dependencies([print_op]):\n",
      "          out = tf.add(tensor, tensor)\n",
      "        sess.run(out)\n",
      "    ```\n",
      "Additionally, to use tf.print in python 2.7, users must make sure to import\n",
      "the following:\n",
      "\n",
      "  `from __future__ import print_function`\n",
      "\n",
      "Tensor(\"add_5:0\", dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print things\n",
    "tf.Print(t, [t])  # This does nothing\n",
    "t = tf.Print(t, [t])  # Here we are using the value returned by tf.Print\n",
    "result = t + 1  # Now when result is evaluated the value of `t` will be printed.\n",
    "print(result)\n",
    "result.eval(session=sess, feed_dict={p:2.0}) # This will print result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='variables'></a>\n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "# Variables\n",
    "\n",
    "Best way to represent shared, persistant states manipulated by program. tf.Variable class. Exist outside the context of a session run (unlike tensors). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Variable\n",
    "\n",
    "tf.get_variable(name, shape)\n",
    "\n",
    "defaults to tf.float32, uniform random initilization.\n",
    "* Can be optionally specified\n",
    "* Can't over-ride variables that have already been created without changing the tf.variable_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'my_variable:0' shape=(1, 2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'other_variable:0' shape=(2,) dtype=int32_ref>\n"
     ]
    }
   ],
   "source": [
    "# Create a variable\n",
    "# try/excepts just to \n",
    "try:\n",
    "    my_variable = tf.get_variable(\"my_variable\", [1, 2, 3])\n",
    "    print(my_variable)\n",
    "except:\n",
    "    print(my_variable)\n",
    "\n",
    "# Different initialization \n",
    "try:\n",
    "    other_variable = tf.get_variable(\"other_variable\", dtype=tf.int32,initializer=tf.constant([23, 42]))\n",
    "    print(other_variable)\n",
    "except:\n",
    "    print(other_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Collections\n",
    "\n",
    "It's possible to access all variables at once. All get placed into 2 collections:\n",
    "* tf.GraphKeys.GLOBAL_VARIABLES\n",
    "    * Shared across all devices\n",
    "* tf.GraphKeys.TRAINABLE_VARIABLES\n",
    "    * Trained on. IF you don't want it trained, add to LOCAL_VARIABLES\n",
    "    \n",
    "Can also create your own collections, use add_to_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables\n",
      "trainable_variables\n",
      "local_variables\n",
      "<tf.Variable 'other_variable:0' shape=(2,) dtype=int32_ref>\n"
     ]
    }
   ],
   "source": [
    "print(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "print(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "print(tf.GraphKeys.LOCAL_VARIABLES)\n",
    "\n",
    "global_vars = tf.get_collection(\n",
    "    tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "    scope=None\n",
    ")\n",
    "\n",
    "print(global_vars[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'my_local:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'my_local:0' shape=() dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "# Non trained variables\n",
    "try:\n",
    "    my_local = tf.get_variable(\"my_local\", shape=(),\n",
    "                    collections=[tf.GraphKeys.LOCAL_VARIABLES])\n",
    "except:\n",
    "    1\n",
    "    \n",
    "try:\n",
    "    my_non_trainable = tf.get_variable(\"my_non_trainable\",\n",
    "                                   shape=(),\n",
    "                                   trainable=False)\n",
    "except: \n",
    "    1\n",
    "\n",
    "trainable_vars = tf.get_collection(\n",
    "    tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "    scope=None\n",
    ")\n",
    "\n",
    "local_vars = tf.get_collection(\n",
    "    tf.GraphKeys.LOCAL_VARIABLES,\n",
    "    scope=None\n",
    ")\n",
    "\n",
    "print(trainable_vars[-1])\n",
    "print(local_vars[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'my_local:0' shape=() dtype=float32_ref>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create your own collection\n",
    "tf.add_to_collection(\"my_collection_name\", my_local)\n",
    "tf.get_collection(\"my_collection_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Variables\n",
    "\n",
    "To do all in one go:\n",
    "* tf.global_variables_initializer()\n",
    "* random initialization to everything in tf.GraphKeys.GLOBAL_VARIABLES\n",
    "\n",
    "To do yourself:\n",
    "* variable.initializer\n",
    "\n",
    "Can get errors if variable depends on other variables.\n",
    "* Use variable.initialzed_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'my_local']\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "# Now all variables are initialized.\n",
    "\n",
    "# Or do your own:\n",
    "sess.run(my_variable.initializer)\n",
    "\n",
    "# Check which hasn't been initalized\n",
    "print(sess.run(tf.report_uninitialized_variables()))\n",
    "\n",
    "# When being careful with making sure things are initialized in the right order\n",
    "try:\n",
    "    v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\n",
    "    w = tf.get_variable(\"w\", initializer=v.initialized_value() + 1)\n",
    "except:\n",
    "    1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Variables\n",
    "\n",
    "Treat like a normal tf.Tensor\n",
    "\n",
    "To add value: use methods assign, assign_add, friends\n",
    "\n",
    "TF optimizers have built in operations to efficiently update values of variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Tensor(\"read:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Just like a tensor\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\n",
    "        w = v + 1  # w is a tf.Tensor which is computed based on the value of v.\n",
    "               # Any time a variable is used in an expression it gets automatically\n",
    "               # converted to a tf.Tensor representing its value.\n",
    "    except: \n",
    "        1\n",
    "\n",
    "    # Assigning values\n",
    "    assignment = v.assign_add(1)\n",
    "    tf.global_variables_initializer().run(session=sess)\n",
    "    print(sess.run(assignment))  # or assignment.op.run(), or assignment.eval()\n",
    "\n",
    "    # Checking value \n",
    "    assignment = v.assign_add(1)\n",
    "    with tf.control_dependencies([assignment]):\n",
    "        w = v.read_value()  # w is guaranteed to reflect v's value after the\n",
    "        print(w)                  # assign_add operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing Variables\n",
    "\n",
    "Two methods:\n",
    "* Explicitly pass variables around\n",
    "* Implicitly wrap within the variable_scope object \n",
    "\n",
    "Possible errors:\n",
    "* Trying to overwrite variables name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example convolutional layer\n",
    "# Nice and clean/concise variable names (weights and biases)\n",
    "def conv_relu(input, kernel_shape, bias_shape):\n",
    "    # Create variable named \"weights\".\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape,\n",
    "        initializer=tf.random_normal_initializer())\n",
    "    # Create variable named \"biases\".\n",
    "    biases = tf.get_variable(\"biases\", bias_shape,\n",
    "        initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)\n",
    "\n",
    "# however, fails in that tf will not know whether to reuse the weights/biases or not everytime conv_relu is called\n",
    "\n",
    "# FIX: Call conv_relu within different scopes\n",
    "def my_image_filter(input_images):\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "        relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        # Variables created here will be named \"conv2/weights\", \"conv2/biases\".\n",
    "        return conv_relu(relu1, [5, 5, 32, 32], [32])\n",
    "    \n",
    "input1 = tf.zeros([5, 5, 32, 32])    \n",
    "input2 = tf.zeros([5, 5, 32, 32])    \n",
    "\n",
    "# If you wish to reuse variables: create a scope with the same name\n",
    "with tf.variable_scope(\"model5\"):\n",
    "    output1 = my_image_filter(input1)\n",
    "with tf.variable_scope(\"model5\", reuse=True):\n",
    "    output2 = my_image_filter(input2)\n",
    "    \n",
    "# Or create a scope using reuse_variable\n",
    "with tf.variable_scope(\"model3\") as scope:\n",
    "    output1 = my_image_filter(input1)\n",
    "    scope.reuse_variables()\n",
    "    output2 = my_image_filter(input2)\n",
    "    \n",
    "# Or reuse a scope name\n",
    "with tf.variable_scope(\"model4\") as scope:\n",
    "    output1 = my_image_filter(input1)\n",
    "with tf.variable_scope(scope, reuse=True):\n",
    "    output2 = my_image_filter(input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graphs\"></a>\n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "# Graphs and Sessions\n",
    "\n",
    "1. Define dataflow graph\n",
    "    * Nodes = computations\n",
    "    * Edges = data\n",
    "    * Parellelisable\n",
    "    * Distributed execution\n",
    "    * Compilation \n",
    "    * Portability\n",
    "\n",
    "2. tf Graphs\n",
    "    * Contain graph structure (nodes and edges)\n",
    "    * Graph collections (collections of metadata)\n",
    "    * Building:\n",
    "        * Construct new tf.Operations (nodes) and tf.Tensor (edge) objects\n",
    "        * Add them to a tf.Graph instance\n",
    "    * EXAMPLE:\n",
    "        * call tf.constant(42) creates an operation (produce 42)\n",
    "        * adds to default graph\n",
    "        * returns a tensor that represents the value\n",
    "    * Calling tf.train.Optimizer.minimze \n",
    "        * Adds operations and tensors to default graph that will calculate gradiations\n",
    "        * Returns an operation that will apply gradients\n",
    "    * default graph\n",
    "        * implicit argument to all API functions\n",
    "   \n",
    "3. Create TensorFlow session to run parts of graph across local/remote devices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming Operations\n",
    "\n",
    "tf.name_scope allows you to add name scope to make names that are more sensible than tf defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding name scopes\n",
    "\n",
    "c_0 = tf.constant(0, name=\"c\")  # => operation named \"c\"\n",
    "\n",
    "# Already-used names will be \"uniquified\".\n",
    "c_1 = tf.constant(2, name=\"c\")  # => operation named \"c_1\"\n",
    "\n",
    "# Name scopes add a prefix to all operations created in the same context.\n",
    "with tf.name_scope(\"outer\"):\n",
    "    c_2 = tf.constant(2, name=\"c\")  # => operation named \"outer/c\"\n",
    "\n",
    "    # Name scopes nest like paths in a hierarchical file system.\n",
    "    with tf.name_scope(\"inner\"):\n",
    "        c_3 = tf.constant(3, name=\"c\")  # => operation named \"outer/inner/c\"\n",
    "\n",
    "    # Exiting a name scope context will return to the previous prefix.\n",
    "    c_4 = tf.constant(4, name=\"c\")  # => operation named \"outer/c_1\"\n",
    "\n",
    "    # Already-used name scopes will be \"uniquified\".\n",
    "    with tf.name_scope(\"inner\"):\n",
    "        c_5 = tf.constant(5, name=\"c\")  # => operation named \"outer/inner_1/c\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placing Operations on Devices\n",
    "\n",
    "tf.device allows you to easily spread over devices\n",
    "\n",
    "can automatically pin operations onto different machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations created outside either context will run on the \"best possible\"\n",
    "# device. For example, if you have a GPU and a CPU available, and the operation\n",
    "# has a GPU implementation, TensorFlow will choose the GPU.\n",
    "weights = tf.random_normal([2,2,1])\n",
    "\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "  # Operations created in this context will be pinned to the CPU.\n",
    "  img = tf.cast(tf.image.decode_png(tf.read_file(\"../Images/cnn.png\")),tf.float32)\n",
    "\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "  # Operations created in this context will be pinned to the GPU.\n",
    "  result = tf.matmul(weights, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions\n",
    "\n",
    "Connects tf.graph to the cpp runtime. \n",
    "\n",
    "Can either use with tf.Session() as sess: or open/close a session (like opening/closing a file). \n",
    "\n",
    "3 arguments:\n",
    "* target (default is local machine)\n",
    "* graph (default is default graph)\n",
    "* config \n",
    "\n",
    "Run sessions with tf.Session.run\n",
    "* must specify a list of fetches to determine return values (what parts of graph need to be run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a default in-process session.\n",
    "with tf.Session() as sess:\n",
    "  # ...\n",
    "    print('Do things')\n",
    "\n",
    "# Create a remote session.\n",
    "with tf.Session(\"grpc://example.org:2222\"):\n",
    "  # ...\n",
    "    print('Do remote things')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Example run session\n",
    "x = tf.constant([[37.0, -23.0], [1.0, 4.0]])\n",
    "w = tf.Variable(tf.random_uniform([2, 2]))\n",
    "y = tf.matmul(x, w)\n",
    "output = tf.nn.softmax(y)\n",
    "init_op = w.initializer\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer on `w`.\n",
    "    sess.run(init_op)\n",
    "\n",
    "    # Evaluate `output`. `sess.run(output)` will return a NumPy array containing\n",
    "    # the result of the computation.\n",
    "    print(sess.run(output))\n",
    "\n",
    "    # Evaluate `y` and `output`. Note that `y` will only be computed once, and its\n",
    "    # result used both to return `y_val` and as an input to the `tf.nn.softmax()`\n",
    "    # op. Both `y_val` and `output_val` will be NumPy arrays.\n",
    "    y_val, output_val = sess.run([y, output])\n",
    "    \n",
    "    \n",
    "# Using dictionary of feeds\n",
    "# Define a placeholder that expects a vector of three floating-point values,\n",
    "# and a computation that depends on it.\n",
    "x = tf.placeholder(tf.float32, shape=[3])\n",
    "y = tf.square(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Feeding a value changes the result that is returned when you evaluate `y`.\n",
    "    print(sess.run(y, {x: [1.0, 2.0, 3.0]}))  # => \"[1.0, 4.0, 9.0]\"\n",
    "    print(sess.run(y, {x: [0.0, 0.0, 5.0]}))  # => \"[0.0, 0.0, 25.0]\"\n",
    "\n",
    "    # Raises <a href=\"./../api_docs/python/tf/errors/InvalidArgumentError\"><code>tf.errors.InvalidArgumentError</code></a>, because you must feed a value for\n",
    "    # a `tf.placeholder()` when evaluating a tensor that depends on it.\n",
    "    #sess.run(y)\n",
    "\n",
    "    # Raises `ValueError`, because the shape of `37.0` does not match the shape\n",
    "    # of placeholder `x`.\n",
    "    #sess.run(y, {x: 37.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Visualization\n",
    "\n",
    "Uses TensorBoard\n",
    "\n",
    "from command line:\n",
    "* tensorboard --logdir=/path/to/logdir\n",
    "* then navigate to localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Build your graph.\n",
    "x = tf.constant([[37.0, -23.0], [1.0, 4.0]])\n",
    "w = tf.Variable(tf.random_uniform([2, 2]))\n",
    "y = tf.matmul(x, w)\n",
    "# ...\n",
    "loss = tf.losses.mean_squared_error(y,tf.matmul(x,w))\n",
    "train_op = tf.train.AdagradOptimizer(0.01).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # `sess.graph` provides access to the graph used in a <a href=\"./../api_docs/python/tf/Session\"><code>tf.Session</code></a>.\n",
    "    writer = tf.summary.FileWriter(\"/tmp/log/...\", sess.graph)\n",
    "\n",
    "    # Perform your computation...\n",
    "    for i in range(1000):\n",
    "        sess.run(train_op)\n",
    "    # ...\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming with Multiple Graphs\n",
    "\n",
    "Multiple graphs can be named and used within a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "g_1 = tf.Graph()\n",
    "with g_1.as_default():\n",
    "  # Operations created in this scope will be added to `g_1`.\n",
    "  c = tf.constant(\"Node in g_1\")\n",
    "\n",
    "  # Sessions created in this scope will run operations from `g_1`.\n",
    "  sess_1 = tf.Session()\n",
    "\n",
    "g_2 = tf.Graph()\n",
    "with g_2.as_default():\n",
    "  # Operations created in this scope will be added to `g_2`.\n",
    "  d = tf.constant(\"Node in g_2\")\n",
    "\n",
    "# Alternatively, you can pass a graph when constructing a <a href=\"./../api_docs/python/tf/Session\"><code>tf.Session</code></a>:\n",
    "# `sess_2` will run operations from `g_2`.\n",
    "sess_2 = tf.Session(graph=g_2)\n",
    "\n",
    "assert c.graph is g_1\n",
    "assert sess_1.graph is g_1\n",
    "\n",
    "assert d.graph is g_2\n",
    "assert sess_2.graph is g_2\n",
    "\n",
    "# Print all of the operations in the default graph.\n",
    "g = tf.get_default_graph()\n",
    "print(g.get_operations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='save'></a>\n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "# Save and Restore\n",
    "\n",
    "tf.train.Saver class. \n",
    "\n",
    "## Save and Restore Variables\n",
    "\n",
    "TF Variables are best way to represent shared states. \n",
    "Saver object runs operations, saves checkpoint files, restores variables, etc.\n",
    "\n",
    "Don't need to initialize restored variables. \n",
    "\n",
    "Can create as many Saver objects as you want/need to save and restore different subsets.\n",
    "\n",
    "Saving variables:\n",
    "* Saver passes all variables in the graph. \n",
    "* Uses name that was passed when it was created. \n",
    "* Can change these default settings to pass a subset/rename variables.\n",
    "    * Use a lsit of variables or python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Save variables\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", shape=[3], initializer = tf.zeros_initializer)\n",
    "v2 = tf.get_variable(\"v2\", shape=[5], initializer = tf.zeros_initializer)\n",
    "\n",
    "inc_v1 = v1.assign(v1+1)\n",
    "dec_v2 = v2.assign(v2-1)\n",
    "\n",
    "# Add an op to initialize the variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, and save the\n",
    "# variables to disk.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    # Do some work with the model.\n",
    "    inc_v1.op.run()\n",
    "    dec_v2.op.run()\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Model restored.\n",
      "v1 : [1. 1. 1.]\n",
      "v2 : [-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Restore Variables\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", shape=[3])\n",
    "v2 = tf.get_variable(\"v2\", shape=[5])\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    # Check the values of the variables\n",
    "    print(\"v1 : %s\" % v1.eval())\n",
    "    print(\"v2 : %s\" % v2.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "v1 : [0. 0. 0.]\n",
      "v2 : [-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Save a subset\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", [3], initializer = tf.zeros_initializer)\n",
    "v2 = tf.get_variable(\"v2\", [5], initializer = tf.zeros_initializer)\n",
    "\n",
    "# Add ops to save and restore only `v2` using the name \"v2\"\n",
    "saver = tf.train.Saver({\"v2\": v2})\n",
    "\n",
    "# Use the saver object normally after that.\n",
    "with tf.Session() as sess:\n",
    "    # Initialize v1 since the saver will not.\n",
    "    v1.initializer.run()\n",
    "    saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "\n",
    "    print(\"v1 : %s\" % v1.eval())\n",
    "    print(\"v2 : %s\" % v2.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect a Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print all tensors\n",
      "tensor_name:  v1\n",
      "[1. 1. 1.]\n",
      "tensor_name:  v2\n",
      "[-1. -1. -1. -1. -1.]\n",
      "\n",
      "Print only v1\n",
      "tensor_name:  v1\n",
      "[1. 1. 1.]\n",
      "\n",
      "Print only v2\n",
      "tensor_name:  v2\n",
      "[-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# import the inspect_checkpoint library\n",
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "\n",
    "\n",
    "# print all tensors in checkpoint file\n",
    "print('Print all tensors')\n",
    "chkp.print_tensors_in_checkpoint_file(\"/tmp/model.ckpt\", tensor_name='', all_tensors=True)\n",
    "print()\n",
    "\n",
    "# tensor_name:  v1\n",
    "# [ 1.  1.  1.]\n",
    "# tensor_name:  v2\n",
    "# [-1. -1. -1. -1. -1.]\n",
    "\n",
    "# print only tensor v1 in checkpoint file\n",
    "print('Print only v1')\n",
    "chkp.print_tensors_in_checkpoint_file(\"/tmp/model.ckpt\", tensor_name='v1', all_tensors=False)\n",
    "print()\n",
    "\n",
    "# tensor_name:  v1\n",
    "# [ 1.  1.  1.]\n",
    "\n",
    "# print only tensor v2 in checkpoint file\n",
    "print('Print only v2')\n",
    "chkp.print_tensors_in_checkpoint_file(\"/tmp/model.ckpt\", tensor_name='v2', all_tensors=False)\n",
    "\n",
    "# tensor_name:  v2\n",
    "# [-1. -1. -1. -1. -1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Restore Models\n",
    "\n",
    "Uses SavedModel instead of Saver.save()/restore() for variables. Language neutral.\n",
    "\n",
    "Saves entire model:\n",
    "* variables\n",
    "* graphs\n",
    "* metadata\n",
    "\n",
    "Loading a Saved Model\n",
    "* requires the session in which to restore and\n",
    "* tags to identifty Meta-Graph stuff and\n",
    "* location\n",
    "\n",
    "Structure of SavedModel Directory:\n",
    "\n",
    "assets/  \n",
    "assets.extra/    \n",
    "variables/  \n",
    "    variables.data-?????-of-?????  \n",
    "    variables.index  \n",
    "saved_model.pb|saved_model.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: TF_Example_SaveModel_2\\saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "# Simple save\n",
    "original = 'TF_Example_SaveModel'\n",
    "count = 0\n",
    "path_name = original+'_'+str(count)\n",
    "while os.path.exists(path_name):\n",
    "    path_name = original+'_'+str(count)\n",
    "    count+=1\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "# Create some variables.\n",
    "x = tf.get_variable(\"x\", [5], initializer = tf.zeros_initializer)\n",
    "y = tf.get_variable(\"y\", [5], initializer = tf.zeros_initializer)\n",
    "z = tf.add(x,y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf.saved_model.simple_save(sess,\n",
    "            path_name, # must be an empty or non-existant directory\n",
    "            inputs={\"x\": x, \"y\": y},\n",
    "            outputs={\"z\": z})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from TF_Example_SaveModel_2\\variables\\variables\n"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "export_dir = path_name\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SavedModel and Estimators\n",
    "\n",
    "May want to build a model then create a service that takes requests, returns a result. \n",
    "\n",
    "Need to:\n",
    "\n",
    "1. Specify output notes, corresponding APIs that can be served (classify, regress, predict).\n",
    "2. Export model to SavedModel format\n",
    "3. Serve model from local server and request predictons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line Interface\n",
    "\n",
    "Can use a CLI to inspect and execute a saved model. \n",
    "\n",
    "Works from command line:\n",
    "\n",
    "* Show tags:\n",
    "\n",
    "usage: saved_model_cli show [-h] --dir DIR [--all] [--tag_set TAG_SET] [--signature_def SIGNATURE_DEF_KEY]\n",
    "    \n",
    "* run a graph computation\n",
    "\n",
    "usage: saved_model_cli run [-h] --dir DIR \n",
    "                            --tag_set TAG_SET signature_def\n",
    "                           SIGNATURE_DEF_KEY [--inputs INPUTS]\n",
    "                           [--input_exprs INPUT_EXPRS]\n",
    "                           [--input_examples INPUT_EXAMPLES] [--outdir OUTDIR]\n",
    "                           [--overwrite] [--tf_debug]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
